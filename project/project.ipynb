{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "296bc31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38a67716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham              Will Ì_ b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the CSV file with the correct encoding (latin1 to avoid Unicode errors)\n",
    "df = pd.read_csv(\"spam.csv\", encoding=\"latin1\")\n",
    "\n",
    "# Keep only the first two columns (label and message)\n",
    "df = df.iloc[:, :2]\n",
    "\n",
    "# Rename the columns to meaningful names\n",
    "df.columns = [\"label\", \"text\"]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c83d1a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label    0\n",
       "text     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8e80800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(403)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "996d549a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48f161d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9920982f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5169, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a799595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dtypes</th>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nunique</th>\n",
       "      <td>2</td>\n",
       "      <td>5169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          label    text\n",
       "dtypes   object  object\n",
       "nunique       2    5169"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show number of unique values in each column and their datatypes\n",
    "dtypes=df.dtypes\n",
    "nuniq=df.nunique()\n",
    "pd.DataFrame({'dtypes':dtypes,'nunique':nuniq}).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d37cbfe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>category</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label    text\n",
       "0  category  object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert some columns into category datatype\n",
    "col=[\"label\"]\n",
    "df[col]=df[col].astype('category')\n",
    "pd.DataFrame(df.dtypes).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47337ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to 0/1\n",
    "df[\"label\"] = df[\"label\"].map({\"ham\": 0, \"spam\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8ac68ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0     0  Go until jurong point, crazy.. Available only ...\n",
       "1     0                      Ok lar... Joking wif u oni...\n",
       "2     1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3     0  U dun say so early hor... U c already then say...\n",
       "4     0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9db0473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>go until jurong point, crazy.. available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>ok lar... joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>u dun say so early hor... u c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>nah i don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0     0  go until jurong point, crazy.. available only ...\n",
       "1     0                      ok lar... joking wif u oni...\n",
       "2     1  free entry in 2 a wkly comp to win fa cup fina...\n",
       "3     0  u dun say so early hor... u c already then say...\n",
       "4     0  nah i don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert all text to lowercase\n",
    "df[\"text\"] = df[\"text\"].str.lower()\n",
    "\n",
    "df[[\"label\", \"text\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d03d65c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>u dun say so early hor u c already then say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>nah i dont think he goes to usf he lives aroun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0     0  go until jurong point crazy available only in ...\n",
       "1     0                            ok lar joking wif u oni\n",
       "2     1  free entry in 2 a wkly comp to win fa cup fina...\n",
       "3     0        u dun say so early hor u c already then say\n",
       "4     0  nah i dont think he goes to usf he lives aroun..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "# Remove punctuation from text\n",
    "df[\"text\"] = df[\"text\"].apply(lambda x: x.translate(str.maketrans(\"\", \"\", string.punctuation)))\n",
    "\n",
    "df[[\"label\", \"text\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e632020",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mms2023\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\mms2023\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[go, until, jurong, point, crazy, available, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[free, entry, in, 2, a, wkly, comp, to, win, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[u, dun, say, so, early, hor, u, c, already, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[nah, i, dont, think, he, goes, to, usf, he, l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0     0  [go, until, jurong, point, crazy, available, o...\n",
       "1     0                     [ok, lar, joking, wif, u, oni]\n",
       "2     1  [free, entry, in, 2, a, wkly, comp, to, win, f...\n",
       "3     0  [u, dun, say, so, early, hor, u, c, already, t...\n",
       "4     0  [nah, i, dont, think, he, goes, to, usf, he, l..."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"punkt_tab\")\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Tokenize the text\n",
    "df[\"text\"] = df[\"text\"].apply(word_tokenize)\n",
    "\n",
    "df[[\"label\", \"text\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1596779",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mms2023\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[nah, dont, think, goes, usf, lives, around, t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0     0  [go, jurong, point, crazy, available, bugis, n...\n",
       "1     0                     [ok, lar, joking, wif, u, oni]\n",
       "2     1  [free, entry, 2, wkly, comp, win, fa, cup, fin...\n",
       "3     0      [u, dun, say, early, hor, u, c, already, say]\n",
       "4     0  [nah, dont, think, goes, usf, lives, around, t..."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "# Remove stopwords from tokens\n",
    "df[\"text\"] = df[\"text\"].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "\n",
    "df[[\"label\", \"text\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38568457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[free, entry, wkly, comp, win, fa, cup, final,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[nah, dont, think, goes, usf, lives, around, t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0     0  [go, jurong, point, crazy, available, bugis, n...\n",
       "1     0                     [ok, lar, joking, wif, u, oni]\n",
       "2     1  [free, entry, wkly, comp, win, fa, cup, final,...\n",
       "3     0      [u, dun, say, early, hor, u, c, already, say]\n",
       "4     0  [nah, dont, think, goes, usf, lives, around, t..."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove numbers from tokens\n",
    "df[\"text\"] = df[\"text\"].apply(lambda x: [word for word in x if not word.isdigit()])\n",
    "\n",
    "df[[\"label\", \"text\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d4f67b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mms2023\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\mms2023\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[free, entry, wkly, comp, win, fa, cup, final,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[nah, dont, think, go, usf, life, around, though]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0     0  [go, jurong, point, crazy, available, bugis, n...\n",
       "1     0                     [ok, lar, joking, wif, u, oni]\n",
       "2     1  [free, entry, wkly, comp, win, fa, cup, final,...\n",
       "3     0      [u, dun, say, early, hor, u, c, already, say]\n",
       "4     0  [nah, dont, think, go, usf, life, around, though]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"omw-1.4\")\n",
    "\n",
    "# Initialize lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Apply Lemmatization on tokenized lists\n",
    "df[\"text\"] = df[\"text\"].apply(lambda tokens: [lemmatizer.lemmatize(word) for word in tokens])\n",
    "\n",
    "# Show the updated dataframe\n",
    "df[[\"label\", \"text\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "85918f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join tokens back to single string for vectorizers\n",
    "df[\"text\"] = df[\"text\"].apply(lambda tokens: \" \".join(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ada4054",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\mms2023\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>pos_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "      <td>[(go, VB), (jurong, JJ), (point, NN), (crazy, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "      <td>[(ok, JJ), (lar, JJ), (joking, NN), (wif, NN),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>free entry wkly comp win fa cup final tkts 21s...</td>\n",
       "      <td>[(free, JJ), (entry, NN), (wkly, VBD), (comp, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u dun say early hor u c already say</td>\n",
       "      <td>[(u, JJ), (dun, NNS), (say, VBP), (early, JJ),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nah dont think go usf life around though</td>\n",
       "      <td>[(nah, JJ), (dont, NN), (think, VBP), (go, VB)...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  go jurong point crazy available bugis n great ...   \n",
       "1                            ok lar joking wif u oni   \n",
       "2  free entry wkly comp win fa cup final tkts 21s...   \n",
       "3                u dun say early hor u c already say   \n",
       "4           nah dont think go usf life around though   \n",
       "\n",
       "                                            pos_tags  \n",
       "0  [(go, VB), (jurong, JJ), (point, NN), (crazy, ...  \n",
       "1  [(ok, JJ), (lar, JJ), (joking, NN), (wif, NN),...  \n",
       "2  [(free, JJ), (entry, NN), (wkly, VBD), (comp, ...  \n",
       "3  [(u, JJ), (dun, NNS), (say, VBP), (early, JJ),...  \n",
       "4  [(nah, JJ), (dont, NN), (think, VBP), (go, VB)...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"averaged_perceptron_tagger\")\n",
    "\n",
    "# Create a new column for POS tags without modifying original text\n",
    "df[\"pos_tags\"] = df[\"text\"].apply(lambda x: nltk.pos_tag(x.split()))\n",
    "\n",
    "df[[\"text\", \"pos_tags\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ef607c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mms2023\\AppData\\Local\\Temp\\ipykernel_13844\\21252579.py:14: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Combine all messages into a single string\n",
    "all_text = \" \".join(df[\"text\"])\n",
    "\n",
    "# Generate a word cloud from the combined text\n",
    "wordcloud = WordCloud(width=800, height=400, background_color=\"white\").generate(all_text)\n",
    "\n",
    "# Display the word cloud\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "10bb5d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5169, 8321)\n"
     ]
    }
   ],
   "source": [
    "# Bag of Words (BoW) \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X_bow = vectorizer.fit_transform(df[\"text\"])\n",
    "\n",
    "print(X_bow.shape)  # (num_messages, num_unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b709ae88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5169, 8321)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize the TF-IDF Vectorizer\n",
    "# This will transform the text into numerical features\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "# Fit the vectorizer on the \"text\" column and transform it into a sparse matrix\n",
    "X_tfidf = tfidf.fit_transform(df[\"text\"])\n",
    "\n",
    "# Print the shape of the matrix -> (number of rows, number of unique words)\n",
    "print(X_tfidf.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "#word embeddings\n",
    "# Load spaCy English model with word vectors\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "# Replace text column with embeddings (numerical vector)\n",
    "df[\"text_vector\"] = df[\"text\"].apply(lambda x: nlp(x).vector)\n",
    "\n",
    "# Show shape of first vector\n",
    "df[\"text_vector\"].iloc[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bfb46e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mms2023\\AppData\\Local\\Temp\\ipykernel_13844\\3054629834.py:10: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Count plot for label distribution\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x=\"label\", data=df)\n",
    "plt.title(\"Number of Ham vs Spam Messages\")\n",
    "plt.xlabel(\"Label (0=Ham, 1=Spam)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "59e60892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE: [4516  653]\n",
      "After SMOTE: [4516 4516]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "\n",
    "# Convert series of text embeddings to a 2D numpy array\n",
    "X = np.stack(df[\"text_vector\"].values)\n",
    "y = df[\"label\"].values\n",
    "\n",
    "# Apply SMOTE to balance the classes\n",
    "# This generates synthetic samples for the minority class\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Print class distribution before and after SMOTE\n",
    "print(\"Before SMOTE:\", np.bincount(y))\n",
    "print(\"After SMOTE:\", np.bincount(y_resampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b1dc731f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mms2023\\AppData\\Local\\Temp\\ipykernel_13844\\4152554772.py:10: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a DataFrame from y_res (resampled labels)\n",
    "df_resampled = pd.DataFrame({'label': y_resampled})\n",
    "\n",
    "# Count plot to check if classes are balanced after SMOTE\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x='label', data=df_resampled)\n",
    "plt.title(\"Number of Ham vs Spam Messages After SMOTE\")\n",
    "plt.xlabel(\"Label (0=Ham, 1=Spam)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "59d9a531",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize StandardScaler for normalization\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the resampled data and transform\n",
    "X_rescaled = scaler.fit_transform(X_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4a9b4073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (7225, 300)\n",
      "X_test shape: (1807, 300)\n",
      "y_train distribution: [3612 3613]\n",
      "y_test distribution: [904 903]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the balanced data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_rescaled,         # Features after SMOTE\n",
    "    y_resampled,         # Labels after SMOTE\n",
    "    test_size=0.2, # 20% data for testing\n",
    "    random_state=42,\n",
    "    stratify=y_resampled # Keep class balance in both train and test\n",
    ")\n",
    "\n",
    "# Print the shapes to verify\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train distribution:\", np.bincount(y_train))\n",
    "print(\"y_test distribution:\", np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "589daf4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Decision Tree ---\n",
      "Train Accuracy: 0.9837\n",
      "Test Accuracy: 0.9247\n",
      "\n",
      "--- Random Forest ---\n",
      "Train Accuracy: 0.9917\n",
      "Test Accuracy: 0.9768\n",
      "\n",
      "--- XGBoost ---\n",
      "Train Accuracy: 0.9992\n",
      "Test Accuracy: 0.9862\n",
      "\n",
      "--- Logistic Regression ---\n",
      "Train Accuracy: 0.9564\n",
      "Test Accuracy: 0.9286\n",
      "\n",
      "--- SVM ---\n",
      "Train Accuracy: 0.9633\n",
      "Test Accuracy: 0.9319\n",
      "\n",
      "--- Perceptron ---\n",
      "Train Accuracy: 0.9230\n",
      "Test Accuracy: 0.9054\n",
      "\n",
      "--- MLP ---\n",
      "Train Accuracy: 0.9988\n",
      "Test Accuracy: 0.9878\n",
      "\n",
      "--- Classification Report Comparison ---\n",
      "          metric  precision    recall  f1-score      support  \\\n",
      "0              0   0.962651  0.883850  0.921569   904.000000   \n",
      "1              1   0.892528  0.965670  0.927660   903.000000   \n",
      "2       accuracy   0.924737  0.924737  0.924737     0.924737   \n",
      "3      macro avg   0.927589  0.924760  0.924614  1807.000000   \n",
      "4   weighted avg   0.927609  0.924737  0.924612  1807.000000   \n",
      "5              0   0.989773  0.963496  0.976457   904.000000   \n",
      "6              1   0.964401  0.990033  0.977049   903.000000   \n",
      "7       accuracy   0.976757  0.976757  0.976757     0.976757   \n",
      "8      macro avg   0.977087  0.976764  0.976753  1807.000000   \n",
      "9   weighted avg   0.977094  0.976757  0.976753  1807.000000   \n",
      "10             0   0.993266  0.978982  0.986072   904.000000   \n",
      "11             1   0.979258  0.993355  0.986256   903.000000   \n",
      "12      accuracy   0.986165  0.986165  0.986165     0.986165   \n",
      "13     macro avg   0.986262  0.986169  0.986164  1807.000000   \n",
      "14  weighted avg   0.986266  0.986165  0.986164  1807.000000   \n",
      "15             0   0.942857  0.912611  0.927487   904.000000   \n",
      "16             1   0.915236  0.944629  0.929700   903.000000   \n",
      "17      accuracy   0.928611  0.928611  0.928611     0.928611   \n",
      "18     macro avg   0.929047  0.928620  0.928594  1807.000000   \n",
      "19  weighted avg   0.929054  0.928611  0.928593  1807.000000   \n",
      "20             0   0.947308  0.914823  0.930782   904.000000   \n",
      "21             1   0.917559  0.949059  0.933043   903.000000   \n",
      "22      accuracy   0.931931  0.931931  0.931931     0.931931   \n",
      "23     macro avg   0.932434  0.931941  0.931913  1807.000000   \n",
      "24  weighted avg   0.932442  0.931931  0.931912  1807.000000   \n",
      "25             0   0.900546  0.911504  0.905992   904.000000   \n",
      "26             1   0.910314  0.899225  0.904735   903.000000   \n",
      "27      accuracy   0.905368  0.905368  0.905368     0.905368   \n",
      "28     macro avg   0.905430  0.905365  0.905364  1807.000000   \n",
      "29  weighted avg   0.905427  0.905368  0.905364  1807.000000   \n",
      "30             0   1.000000  0.975664  0.987682   904.000000   \n",
      "31             1   0.976216  1.000000  0.987965   903.000000   \n",
      "32      accuracy   0.987825  0.987825  0.987825     0.987825   \n",
      "33     macro avg   0.988108  0.987832  0.987823  1807.000000   \n",
      "34  weighted avg   0.988115  0.987825  0.987823  1807.000000   \n",
      "\n",
      "                  model  \n",
      "0         Decision Tree  \n",
      "1         Decision Tree  \n",
      "2         Decision Tree  \n",
      "3         Decision Tree  \n",
      "4         Decision Tree  \n",
      "5         Random Forest  \n",
      "6         Random Forest  \n",
      "7         Random Forest  \n",
      "8         Random Forest  \n",
      "9         Random Forest  \n",
      "10              XGBoost  \n",
      "11              XGBoost  \n",
      "12              XGBoost  \n",
      "13              XGBoost  \n",
      "14              XGBoost  \n",
      "15  Logistic Regression  \n",
      "16  Logistic Regression  \n",
      "17  Logistic Regression  \n",
      "18  Logistic Regression  \n",
      "19  Logistic Regression  \n",
      "20                  SVM  \n",
      "21                  SVM  \n",
      "22                  SVM  \n",
      "23                  SVM  \n",
      "24                  SVM  \n",
      "25           Perceptron  \n",
      "26           Perceptron  \n",
      "27           Perceptron  \n",
      "28           Perceptron  \n",
      "29           Perceptron  \n",
      "30                  MLP  \n",
      "31                  MLP  \n",
      "32                  MLP  \n",
      "33                  MLP  \n",
      "34                  MLP  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure pandas shows all rows and columns\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# Define all models\n",
    "models = {\n",
    "    \"Decision Tree\": DecisionTreeClassifier(max_depth=10, random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(n_estimators=100, max_depth=10, eval_metric='logloss', random_state=42),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"SVM\": SVC(kernel='linear', probability=True, random_state=42),\n",
    "    \"Perceptron\": Perceptron(max_iter=1000, random_state=42),\n",
    "    \"MLP\": MLPClassifier(hidden_layer_sizes=(100,50), max_iter=500, random_state=42),\n",
    "}\n",
    "\n",
    "# List to store classification reports\n",
    "report_list = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n--- {name} ---\")\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on train and test sets\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Print Accuracy\n",
    "    train_acc = accuracy_score(y_train, y_train_pred)\n",
    "    test_acc = accuracy_score(y_test, y_test_pred)\n",
    "    print(f\"Train Accuracy: {train_acc:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "    \n",
    "    # Classification report for test set\n",
    "    report_dict = classification_report(y_test, y_test_pred, output_dict=True)\n",
    "    \n",
    "    # Convert dict to DataFrame\n",
    "    df_report = pd.DataFrame(report_dict).T.reset_index()\n",
    "    df_report.rename(columns={'index': 'metric'}, inplace=True)\n",
    "    df_report['model'] = name  # Add model name\n",
    "    \n",
    "    report_list.append(df_report)\n",
    "\n",
    "# Combine all reports into a single DataFrame for comparison\n",
    "report_df = pd.concat(report_list, ignore_index=True)\n",
    "\n",
    "# Display comparison table fully\n",
    "print(\"\\n--- Classification Report Comparison ---\")\n",
    "print(report_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09848c6",
   "metadata": {},
   "source": [
    "Best Model Selection Based on the *Test Accuracy* and *Classification Report (Precision, Recall, F1-score)*, the best model for this dataset is:\n",
    "\n",
    "*MLP Classifier*:\n",
    "- *Test Accuracy:* 0.9884  \n",
    "- *F1-score:* High and balanced for both classes (spam and ham)  \n",
    "- *Notes:* Performs best overall compared to other models. Slightly longer training time but excellent predictive performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d6e161a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mms2023\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mms2023\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mms2023\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\mms2023\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model, scaler, and preprocessing saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import spacy\n",
    "import pickle\n",
    "\n",
    "# ------------------------\n",
    "# Download NLTK packages\n",
    "# ------------------------\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"omw-1.4\")\n",
    "\n",
    "# ------------------------\n",
    "# Load spaCy model for embeddings (only for notebook use)\n",
    "# ------------------------\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "# ------------------------\n",
    "# Preprocessing tools\n",
    "# ------------------------\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [w for w in tokens if w not in stop_words]\n",
    "    tokens = [w for w in tokens if not w.isdigit()]\n",
    "    tokens = [lemmatizer.lemmatize(w) for w in tokens]\n",
    "    return tokens\n",
    "\n",
    "# ------------------------\n",
    "# Apply preprocessing\n",
    "# ------------------------\n",
    "df[\"tokens\"] = df[\"text\"].apply(preprocess_text)\n",
    "df[\"clean_text\"] = df[\"tokens\"].apply(lambda x: \" \".join(x))\n",
    "\n",
    "# ------------------------\n",
    "# Create embeddings column\n",
    "# ------------------------\n",
    "df[\"text_vector\"] = df[\"clean_text\"].apply(lambda x: nlp(x).vector)\n",
    "X = np.stack(df[\"text_vector\"].values)\n",
    "y = df[\"label\"].values\n",
    "\n",
    "# ------------------------\n",
    "# Balance classes with SMOTE\n",
    "# ------------------------\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# ------------------------\n",
    "# Normalize features\n",
    "# ------------------------\n",
    "scaler = StandardScaler()\n",
    "X_rescaled = scaler.fit_transform(X_resampled)\n",
    "\n",
    "# ------------------------\n",
    "# Train/test split\n",
    "# ------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_rescaled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled\n",
    ")\n",
    "\n",
    "# ------------------------\n",
    "# Train MLP\n",
    "# ------------------------\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,50), max_iter=500, random_state=42)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# ------------------------\n",
    "# Save everything (WITHOUT nlp!)\n",
    "# ------------------------\n",
    "with open(\"spam_detector_full.pkl\", \"wb\") as f:\n",
    "    pickle.dump({\n",
    "        \"model\": mlp,\n",
    "        \"scaler\": scaler,\n",
    "        \"stop_words\": stop_words,\n",
    "        \"lemmatizer\": lemmatizer\n",
    "    }, f)\n",
    "\n",
    "print(\"✅ Model, scaler, and preprocessing saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
